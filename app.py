import streamlit as st
from faster_whisper import WhisperModel
import torch
import os
import tempfile
import io

# Page config for RTL Urdu support
st.set_page_config(
    page_title="Ø§Ø±Ø¯Ùˆ Ø¢ÚˆÛŒÙˆ Ù¹Ø±Ø§Ù†Ø³Ú©Ø±Ø§Ø¦Ø¨Ø±",
    page_icon="ğŸ‡µğŸ‡°",
    layout="wide",
    initial_sidebar_state="expanded"
)

st.title("ğŸ‡µğŸ‡° Ø§Ø±Ø¯Ùˆ Ø¢ÚˆÛŒÙˆ Ù¹Ø±Ø§Ù†Ø³Ú©Ø±Ø§Ø¦Ø¨Ø±")
st.markdown("**WhatsApp ÙˆØ§Ø¦Ø³ØŒ ÛŒÙˆÙ¹ÛŒÙˆØ¨ØŒ Ù„ÛŒÚ©Ú†Ø± â†’ ÙÙˆØ±Ø§Ù‹ Ø¯Ø±Ø³Øª Ø§Ø±Ø¯Ùˆ Ù…ØªÙ†** | Ù…ÙØª â€¢ ØªÛŒØ² â€¢ Cloud Ù¾Ø± Ú†Ù„ØªØ§ ÛÛ’")

# Sidebar for model selection
st.sidebar.header("Ù…Ø§ÚˆÙ„ Ù…Ù†ØªØ®Ø¨ Ú©Ø±ÛŒÚº")
model_size = st.sidebar.selectbox(
    "Ù…Ø§ÚˆÙ„ Ø³Ø§Ø¦Ø² (Ø¨Ú‘Ø§ = Ø¨ÛØªØ± Ø§Ø±Ø¯ÙˆØŒ Ú†Ú¾ÙˆÙ¹Ø§ = ØªÛŒØ²)",
    ["small", "medium", "large-v3"],
    index=1  # Default: medium
)
use_gpu = st.sidebar.checkbox("GPU Ø§Ø³ØªØ¹Ù…Ø§Ù„ Ú©Ø±ÛŒÚº (Ø§Ú¯Ø± Ø¯Ø³ØªÛŒØ§Ø¨ ÛÙˆ)", value=False)  # CPU safe for Cloud

# Load model (cached, one-time)
@st.cache_resource
def load_whisper_model(size):
    device = "cuda" if torch.cuda.is_available() and use_gpu else "cpu"
    compute_type = "float16" if device == "cuda" else "int8"
    with st.spinner(f"{size} Ù…Ø§ÚˆÙ„ Ù„ÙˆÚˆ ÛÙˆ Ø±ÛØ§ ÛÛ’... (ØµØ±Ù Ù¾ÛÙ„ÛŒ Ø¨Ø§Ø±)"):
        return WhisperModel(size, device=device, compute_type=compute_type)

model = load_whisper_model(model_size)
st.sidebar.success("Ù…Ø§ÚˆÙ„ ØªÛŒØ§Ø±!")

# File uploader (restrict to audio/video)
uploaded_file = st.file_uploader(
    "Ø§Ù¾Ù†ÛŒ Ø¢ÚˆÛŒÙˆ/ÙˆÛŒÚˆÛŒÙˆ ÙØ§Ø¦Ù„ ÚˆØ§Ù„ÛŒÚº",
    type=["mp3", "m4a", "wav", "ogg", "mp4", "webm", "mov", "flac"],
    help="Ø³Ø¨ Ø³Û’ Ø¨ÛØªØ±: m4a (WhatsApp) ÛŒØ§ mp3 (ÛŒÙˆÙ¹ÛŒÙˆØ¨)"
)

if uploaded_file is not None:
    # FIXED: Save to temp file path (key fix for av.open() error)
    with tempfile.NamedTemporaryFile(delete=False, suffix=f".{uploaded_file.name.split('.')[-1]}") as tmp_file:
        tmp_file.write(uploaded_file.getvalue())
        audio_path = tmp_file.name

    # Preview audio
    st.audio(uploaded_file, format="audio/mpeg")

    # Transcribe button for control
    if st.button("Ø§Ø±Ø¯Ùˆ Ù…ÛŒÚº Ù¹Ø±Ø§Ù†Ø³Ú©Ø±ÛŒÙ¾Ù¹ Ú©Ø±ÛŒÚº", type="primary"):
        with st.spinner("Ø§Ø±Ø¯Ùˆ Ù…ÛŒÚº Ù¹Ø±Ø§Ù†Ø³Ú©Ø±ÛŒÙ¾Ø´Ù† ÛÙˆ Ø±ÛÛŒ ÛÛ’... (large-v3 = Ú©Ù…Ø§Ù„)"):
            try:
                # FIXED: Pass file path (string) â€“ no direct file object!
                segments, info = model.transcribe(
                    audio_path,  # Path, not file object
                    language="ur",  # Urdu
                    vad_filter=True,  # Remove silence
                    beam_size=7  # Better accuracy
                )
                
                full_text = " ".join([seg.text.strip() for seg in segments])
                
                # Simple post-processing for Urdu (fix common Whisper errors)
                full_text = full_text.replace("Ú¾Û’", "ÛÛ’").replace("Ø§Ø¬", "Ø¢Ø¬").replace("Ø§Ø±ÛØ§", "Ø¢ Ø±ÛØ§")
                full_text = full_text.replace("Ù„Ø§Ø¦ÛŒ Ù„Ø§Ø¦ÛŒ", "Ù„Ø§Ø¦ Ù„Ø§Ø¦").replace("Ú¾Ùˆ", "ÛÙˆ")
                full_text = re.sub(r'\s+', ' ', full_text).strip()  # Clean spaces

                st.success(f"Ú©Ø§Ù…ÛŒØ§Ø¨! Ø²Ø¨Ø§Ù†: Ø§Ø±Ø¯Ùˆ ({info.language_probability:.1%} ÛŒÙ‚ÛŒÙ†)")

                # Display results
                col1, col2 = st.columns([1, 3])
                with col1:
                    st.metric("Ù„ÙØ¸ÙˆÚº Ú©ÛŒ ØªØ¹Ø¯Ø§Ø¯", len(full_text.split()))
                with col2:
                    st.subheader("Ø®ÙˆØ¨ØµÙˆØ±Øª Ø§Ø±Ø¯Ùˆ Ù…ØªÙ†")
                    st.markdown(f"<div dir='rtl' style='font-size:18px; line-height:1.8; text-align:right;'>{full_text}</div>", unsafe_allow_html=True)

                # Actions
                col1, col2 = st.columns(2)
                with col1:
                    st.download_button(
                        label="Ù…ØªÙ† ÚˆØ§Ø¤Ù† Ù„ÙˆÚˆ Ú©Ø±ÛŒÚº (.txt)",
                        data=full_text,
                        file_name="Ø§Ø±Ø¯Ùˆ_Ù¹Ø±Ø§Ù†Ø³Ú©Ø±ÛŒÙ¾Ø´Ù†.txt",
                        mime="text/plain"
                    )
                with col2:
                    st.code(f"navigator.clipboard.writeText(`{full_text}`);", language="javascript")
                    st.caption("Ø§ÙˆÙ¾Ø± Ú©ÙˆÚˆ Ú©Ø§Ù¾ÛŒ Ú©Ø±Ú©Û’ Ø¨Ø±Ø§Ø¤Ø²Ø± Ú©Ù†Ø³ÙˆÙ„ Ù…ÛŒÚº Ù¾ÛŒØ³Ù¹ Ú©Ø±ÛŒÚº")

            except Exception as e:
                st.error(f"ØºÙ„Ø·ÛŒ: {str(e)}. Ú†ÛŒÚ© Ú©Ø±ÛŒÚº ÙØ§Ø¦Ù„ Ø¯Ø±Ø³Øª ÛÛ’ (ØµØ±Ù Ø¢ÚˆÛŒÙˆ/ÙˆÛŒÚˆÛŒÙˆ).")

        # Cleanup temp file
        finally:
            if os.path.exists(audio_path):
                os.unlink(audio_path)

else:
    st.info("ğŸ“ Ø§ÙˆÙ¾Ø± ÙØ§Ø¦Ù„ ÚˆØ§Ù„ Ú©Ø± 'Ù¹Ø±Ø§Ù†Ø³Ú©Ø±ÛŒÙ¾Ù¹ Ú©Ø±ÛŒÚº' Ø¯Ø¨Ø§Ø¦ÛŒÚºÛ” Ù…Ø«Ø§Ù„: WhatsApp voice note (.m4a)")
    st.markdown("**Ù¹Ù¾**: Ø¨Ú‘ÛŒ ÙØ§Ø¦Ù„Ø² (10+ Ù…Ù†Ù¹) Ú©Û’ Ù„ÛŒÛ’ 'small' Ù…Ø§ÚˆÙ„ Ù…Ù†ØªØ®Ø¨ Ú©Ø±ÛŒÚº â€“ ØªÛŒØ² ÛÙˆ Ø¬Ø§Ø¦Û’ Ú¯ÛŒ!")

# Footer
st.markdown("---")
st.markdown("**Ù¾Ø§Ú©Ø³ØªØ§Ù†ÛŒÙˆÚº Ú©Û’ Ù„ÛŒÛ’ Ø¨Ù†Ø§ÛŒØ§ Ú¯ÛŒØ§** â€¢ faster-whisper + Streamlit Cloud â€¢ 2025")
